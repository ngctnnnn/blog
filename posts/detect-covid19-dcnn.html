<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Detect COVID-19 with Deep Learning | A technical blog</title>
    <meta name="description" content="The official blog">
    <link rel="stylesheet" href="/assets/style.a95e0a9f.css">
    
    <link rel="icon" type="image/x-icon" href="/favicon.ico">
    <meta name="twitter:title" content="Detect COVID-19 with Deep Learning | A technical blog">
    <meta property="og:title" content="Detect COVID-19 with Deep Learning | A technical blog">
  </head>
  <body>
    <div id="app"><div class="antialiased"><div class="flex bg-white"><nav class="z-50 fixed w-full flex justify-center py-3 font-bold bg-white border border-fuchsia-600"><div class="w-full flex justify-between px-4 sm:px-6 xl:max-w-5xl xl:px-0"><a class="text-xl" href="/" aria-label="A technical blog"><img class="inline-block mr-2 spin-img" style="width:36px;height:31px;" alt="logo" src="/logo.svg"><span class="hidden md:inline nav-text">A technical blog</span></a><div class="text-base text-gray-500 leading-5 space-x-6"><a class="hover:text-gray-700 text-xl" href="https://github.com/ngctnnnn/ngctnnnn.github.io" target="_blank" rel="noopener">About us</a></div></div></nav></div><main class="max-w-3xl mx-auto px-4 sm:px-6 xl:max-w-5xl xl:px-0 mt-14"><article class="xl:divide-y xl:divide-gray-200"><header class="pt-6 xl:pb-10 space-y-1 text-center"><dl><dt class="sr-only">Published on</dt><dd class="text-base leading-6 font-medium text-gray-500"><time datetime="2021-08-30T12:00:00.000Z">August 30, 2021</time></dd></dl><h1 class="text-3xl leading-9 font-extrabold text-gray-900 tracking-tight sm:text-4xl sm:leading-10 md:text-5xl md:leading-14">Detect COVID-19 with Deep Learning</h1></header><div class="divide-y xl:divide-y-0 divide-gray-200 xl:grid xl:grid-cols-4 xl:gap-x-10 pb-16 xl:pb-20" style="grid-template-rows:auto 1fr;"><dl class="pt-6 pb-10 xl:pt-11 xl:border-b xl:border-gray-200"><dt class="sr-only">Authors</dt><dd><ul class="flex justify-center xl:block space-x-8 sm:space-x-12 xl:space-x-0 xl:space-y-8"><li class="flex items-center space-x-2"><img src="https://gravatar.com/avatar/6c1ae5231dcadf6b4297a6ddf6315478?s=80" alt="author image" class="w-10 h-10 rounded-full"><dl class="text-sm font-medium leading-5 whitespace-nowrap"><dt class="sr-only">Name</dt><dd class="text-gray-900">Tan Ngoc Pham</dd><dt class="sr-only">Linkedin</dt><dd><a href="https://linkedin.com/in/ngctnnnn" target="_blank" rel="noopnener noreferrer" class="link">@ngctnnnn</a></dd></dl></li></ul></dd></dl><div class="divide-y divide-gray-200 xl:pb-0 xl:col-span-3 xl:row-span-2"><div style="position:relative;" class="prose max-w-none pt-10 pb-8"><div><p>Propose a rapidly testing method which has a high productivity in a short time, which is to use Deep Convolutional Neural Network to detect COVID-19 on Chest X-ray (CXR) images to cope with the present pandemic.</p><hr><h3 id="table-of-contents" tabindex="-1">Table of contents <a class="header-anchor" href="#table-of-contents" aria-hidden="true">#</a></h3><ol><li><a href="#:~:text=1.%20Scientific%20base">Scientific base</a></li><li><a href="#:~:text=2.%20A%20deep%20learning%20based%20approach%20to%20the%20problem">A deep learning based approach to the problem</a></li><li><a href="#:~:text=3.%20Experimental%20results%20and%20evaluation">Experimental results and evaluation</a></li><li><a href="#:~:text=4.%20References">References</a></li></ol><hr><h4 id="_1-scientific-base" tabindex="-1">1. Scientific base <a class="header-anchor" href="#_1-scientific-base" aria-hidden="true">#</a></h4><p>The most crucial thing that make CXR images from pneumonia or COVID-19 patients different from normal ones is the appearance of white spots, whether they are a lot of or a few, on particular positions along patients&#39; lungs. Those white spots are recognized as the term of <em><strong>ground glass opacity</strong></em> or GGO in medical science. Ground glass opacity is the incompletely consolidated injury in patients&#39; lungs. It has a higher density in comparison with surrounded parenchyma while still enables us to observe underlying structures, e.g. blood vessels or bronchial membranes.</p><p align="center"><img src="/covid+pneumonia+normal.png" alt="ground-glass-pattern image"><div align="center"><figcaption><b>Fig 1.</b> Representative CXR images for 3 cases</figcaption><figcaption>COVID-19 (A), Pneumonia (B) and non-respiratory disease (C)</figcaption></div></p><p>A specified doctor in the field of diagnostic imaging could tell that those GGO is the reason for those white spots in the chest radiograph. And a professional radiologist could use these features to differentiate COVID19 with pneumonia patients. Thus, we are capable of using a deep learning network to extract these features, then categorize to give out the appropriate diagnostic results for every cases.</p><h4 id="_2-a-deep-learning-based-approach-to-the-problem" tabindex="-1">2. A deep learning based approach to the problem <a class="header-anchor" href="#_2-a-deep-learning-based-approach-to-the-problem" aria-hidden="true">#</a></h4><p>Throughout the research, we harness the use of 2 different approaches which are <b>ResNet50</b> and <b>VGG19</b> to solve this problem. In addtion, we use <a href="https://github.com/lindawangg/COVID-Net/blob/master/docs/COVIDx.md" target="_blank" rel="noopener noreferrer">COVIDx dataset</a> - which is a widely used dataset in recent research about COVID-19 nowadays.</p><p>VGG19 is a deep neural network architecture under-using residual design principals, it is also a compact architecture which has a low diversity of architectures. On the other hand, ResNet50 is a deep neural network harnessing residual design principles and it has a moderate diversity of architectures. This network brings many a high productivity in a large number of researching in classifying X-ray images.</p><h4 id="_2-1-covidx-dataset" tabindex="-1">2.1 COVIDx Dataset <a class="header-anchor" href="#_2-1-covidx-dataset" aria-hidden="true">#</a></h4><p>COVIDx Datset is a dataset synthesized from 5 different sources. Additionally, this dataset also provides an image extension transfer tool: from <code>.mri</code> into <code>.jpg</code>. And the author moreover provide a code to support data pre-processing and getting rid of unnecessary part for synthesized data.</p><p>The dataset consists of more than 20.000 CXR images from different patients and divided into 2 sets which are training set and testing set. They are also separated into 3 classes which are pneumonia (train: 5963, test: 105), COVID-19 (train: 4649, test: 274) and the healthy (train: 8751, test: 100).</p><p>Our model will get an input of one CXR image and will give out an output as the probability of that image falling into each class which is pneumonia, COVID-19 and healthy, respectively.</p><h4 id="_2-2-detailed-implementation" tabindex="-1">2.2 Detailed implementation <a class="header-anchor" href="#_2-2-detailed-implementation" aria-hidden="true">#</a></h4><p>Both deep learning neural network we proposed which are VGG19 and ResNet50 are all pre-trained on <a href="https://www.image-net.org/" target="_blank" rel="noopener noreferrer">ImageNet</a>. Afterwards, we proceed training process on COVIDx dataset with Adam as the optimization algorithm and the learning rate&#39;s strategy as reducing if the loss on validation set does not improve at all in a long period (patience).</p><p>Detailed implementation: <a href="https://github.com/ngctnnnn/Detect-COVID19" target="_blank" rel="noopener noreferrer">ngctnnnn/Detect-COVID19</a>.</p><p>After implementation, here is my demo for this project:</p><div align="center"><iframe width="560" height="315" src="/demo-covid19.mp4" frameborder="0" allow="accelerometer; autoplay; encrypted-media gyroscope; picture-in-picture" allowfullscreen></iframe></div><h4 id="_3-experimental-results-and-evaluation" tabindex="-1">3. Experimental results and evaluation <a class="header-anchor" href="#_3-experimental-results-and-evaluation" aria-hidden="true">#</a></h4><table><thead><tr><th style="text-align:center;">Disease</th><th style="text-align:center;">Precision</th><th style="text-align:center;">Recall</th><th style="text-align:center;">F1-score</th><th style="text-align:center;">Support</th></tr></thead><tbody><tr><td style="text-align:center;">COVID-19</td><td style="text-align:center;">0.99</td><td style="text-align:center;">0.82</td><td style="text-align:center;">0.90</td><td style="text-align:center;">274</td></tr><tr><td style="text-align:center;">Non-respiratory disease</td><td style="text-align:center;">0.7</td><td style="text-align:center;">0.96</td><td style="text-align:center;">0.81</td><td style="text-align:center;">100</td></tr><tr><td style="text-align:center;">Pneumonia</td><td style="text-align:center;">0.8</td><td style="text-align:center;">0.86</td><td style="text-align:center;">0.83</td><td style="text-align:center;">105</td></tr></tbody></table><div align="center"><b>Table 1. </b>Results on VGG19</div><table><thead><tr><th style="text-align:center;">Disease</th><th style="text-align:center;">Precision</th><th style="text-align:center;">Recall</th><th style="text-align:center;">F1-score</th><th style="text-align:center;">Support</th></tr></thead><tbody><tr><td style="text-align:center;">COVID-19</td><td style="text-align:center;">0.97</td><td style="text-align:center;">0.67</td><td style="text-align:center;">0.79</td><td style="text-align:center;">274</td></tr><tr><td style="text-align:center;">Non-respiratory disease</td><td style="text-align:center;">0.56</td><td style="text-align:center;">0.96</td><td style="text-align:center;">0.71</td><td style="text-align:center;">100</td></tr><tr><td style="text-align:center;">Pneumonia</td><td style="text-align:center;">0.74</td><td style="text-align:center;">0.85</td><td style="text-align:center;">0.79</td><td style="text-align:center;">105</td></tr></tbody></table><div align="center"><b>Table 2. </b>Results on ResNet50 (14 epochs)</div><table><thead><tr><th style="text-align:center;">Disease</th><th style="text-align:center;">Precision</th><th style="text-align:center;">Recall</th><th style="text-align:center;">F1-score</th><th style="text-align:center;">Support</th></tr></thead><tbody><tr><td style="text-align:center;">COVID-19</td><td style="text-align:center;">0.96</td><td style="text-align:center;">0.80</td><td style="text-align:center;">0.88</td><td style="text-align:center;">274</td></tr><tr><td style="text-align:center;">Non-respiratory disease</td><td style="text-align:center;">0.73</td><td style="text-align:center;">0.86</td><td style="text-align:center;">0.79</td><td style="text-align:center;">100</td></tr><tr><td style="text-align:center;">Pneumonia</td><td style="text-align:center;">0.71</td><td style="text-align:center;">0.90</td><td style="text-align:center;">0.79</td><td style="text-align:center;">105</td></tr></tbody></table><div align="center"><b>Table 3. </b>Results on ResNet50 (50 epochs)</div><table><thead><tr><th style="text-align:center;">Architecture</th><th style="text-align:center;">Non-respiratory disease</th><th style="text-align:center;">Pneumonia</th><th style="text-align:center;">COVID-19</th></tr></thead><tbody><tr><td style="text-align:center;">VGG19</td><td style="text-align:center;">96%</td><td style="text-align:center;">86%</td><td style="text-align:center;">82%</td></tr><tr><td style="text-align:center;">ResNet50 (14 epochs)</td><td style="text-align:center;">96%</td><td style="text-align:center;">85%</td><td style="text-align:center;">67%</td></tr><tr><td style="text-align:center;">ResNet50 (50 epochs)</td><td style="text-align:center;">86%</td><td style="text-align:center;">90%</td><td style="text-align:center;">80%</td></tr></tbody></table><div align="center"><b>Table 4. </b>Comparison among models based on sensitivity</div><table><thead><tr><th style="text-align:center;">Architecture</th><th style="text-align:center;">Non-respiratory disease</th><th style="text-align:center;">Pneumonia</th><th style="text-align:center;">COVID-19</th></tr></thead><tbody><tr><td style="text-align:center;">VGG19</td><td style="text-align:center;">70%</td><td style="text-align:center;">80%</td><td style="text-align:center;">99%</td></tr><tr><td style="text-align:center;">ResNet50 (14 epochs)</td><td style="text-align:center;">56%</td><td style="text-align:center;">74%</td><td style="text-align:center;">97%</td></tr><tr><td style="text-align:center;">ResNet50 (50 epochs)</td><td style="text-align:center;">73%</td><td style="text-align:center;">71%</td><td style="text-align:center;">96%</td></tr></tbody></table><div align="center"><b>Table 5. </b>Comparison among models based on PPV</div><table><thead><tr><th style="text-align:center;">Architecture</th><th style="text-align:center;">Number of parameters (M)</th><th style="text-align:center;">Accuracy</th><th style="text-align:center;">Resolution</th></tr></thead><tbody><tr><td style="text-align:center;">VGG19</td><td style="text-align:center;">29.76 trainable + 20.25 non-trainable</td><td style="text-align:center;">86%</td><td style="text-align:center;">480 x 480</td></tr><tr><td style="text-align:center;">ResNet50 (14 epochs)</td><td style="text-align:center;">25.93 trainable + 23.77 non-trainable</td><td style="text-align:center;">77%</td><td style="text-align:center;">224 x 224</td></tr><tr><td style="text-align:center;">ResNet50 (50 epochs)</td><td style="text-align:center;">25.93 trainable + 23.77 non-trainable</td><td style="text-align:center;">84%</td><td style="text-align:center;">224 x 224</td></tr></tbody></table><div align="center"><b>Table 6. </b>Comparison between precision and number of parameters among models</div><h4 id="_4-references" tabindex="-1">4. References <a class="header-anchor" href="#_4-references" aria-hidden="true">#</a></h4><p>[1] A. Chung. <em>Actualmed covid-19 chest x-ray data initiative</em>, 2020, URL: <a href="https://github.com/agchung/Actualmed-COVID-chestxray-dataset" target="_blank" rel="noopener noreferrer">https://ncov.moh.gov.vn</a>.</p><p>[2] J. P. Cohen et al. <em>Covid-19 image data collection</em>, 2020.</p><p>[3] J. Deng et al. <em>Imagenet: A large-scale hierarchicalimage database</em>. In2009 IEEE conference on computer vision and pattern recognition, pages 248–255.Ieee, 2009.</p><p>[4] K. He et al. <em>Deep residual learning for image recognition</em>, 2015.</p><p>[5] Ministry of Health of Vietnam. <em>A page about acute respiratory tract infections covid-19</em>, 2021. URL: <a href="https://ncov.moh.gov.vn" target="_blank" rel="noopener noreferrer">https://ncov.moh.gov.vn</a>.</p><p>[6] Radiological Society of North America. <em>Covid-19 radiography database</em>, 2019. URL: <a href="https://www.kaggle.com/tawsifurrahman/covid19-radiography-database" target="_blank" rel="noopener noreferrer">https://www.kaggle.com/tawsifurrahman/covid19-radiography-database</a>.</p><p>[7] Radiological Society of North America. <em>RSNA pneumonia detection challenge</em>, 2019. URL: <a href="https://www.kaggle.com/c/rsna-pneumonia-detection-challenge/data" target="_blank" rel="noopener noreferrer">https://www.kaggle.com/c/rsna-pneumonia-detection-challenge/data</a>.</p><p>[8] K. Simonyan and A. Zisserman. <em>Very deep convolutional networks for large-scale image recognition</em>, 2015.</p><p>[9] L. Wang, Z. Q. Lin, and A. Wong. <em>Covid-net: a tailored deep convolutional neural network de-sign for detection of covid-19 cases from chest x-ray images.Scientific Reports</em>, 10(1):19549,Nov 2020. ISSN 2045-2322. doi: 10.1038/s41598-020-76550-z. URL: <a href="https://doi.org/10.1038/s41598-020-76550-z" target="_blank" rel="noopener noreferrer">https://doi.org/10.1038/s41598-020-76550-z</a>.</p></div></div></div><footer class="text-sm font-medium leading-5 divide-y divide-gray-200 xl:col-start-1 xl:row-start-2"><div class="pt-8"><a class="link" href="/">← Back to the blog</a></div></footer></div><footer class="text-sm font-medium leading-5 divide-y divide-gray-200 xl:col-start-1 xl:row-start-2" style="display:inline-flex;justify-content:space-between;width:100%;"><div style="display:inline-flex;justify-content:space-between;width:100%;"><!----><div class="py-8"><h2 class="text-xs tracking-wide uppercase text-gray-500"> Next Article </h2><div class="link"><a href="/posts/emotion-recognizing.html">Real-time emotion recognizing →</a></div></div></div></footer></article></main></div></div>
    
    
    
  </body>
</html>