<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Real-time emotion recognizing | A technical blog</title>
    <meta name="description" content="The official blog">
    <link rel="stylesheet" href="/assets/style.181ae394.css">
    
    <link rel="icon" type="image/x-icon" href="/favicon.ico">
    <meta name="twitter:title" content="Real-time emotion recognizing | A technical blog">
    <meta property="og:title" content="Real-time emotion recognizing | A technical blog">
  </head>
  <body>
    <div id="app"><div class="antialiased"><div class="max-w-3xl mx-auto px-4 sm:px-6 xl:max-w-5xl xl:px-0"><nav class="flex justify-between items-center py-10 font-bold"><a class="text-xl" href="/" aria-label="A technical blog"><img class="inline-block mr-2" style="width:36px;height:31px;" alt="logo" src="/logo.svg"><span class="hidden md:inline">A technical blog</span></a><div class="text-base text-gray-500 leading-5"><a class="hover:text-gray-700" href="https://linkedin.com/in/ngctnnnn" target="_blank" rel="noopener">About the author</a></div></nav></div><main class="max-w-3xl mx-auto px-4 sm:px-6 xl:max-w-5xl xl:px-0"><article class="xl:divide-y xl:divide-gray-200"><header class="pt-6 xl:pb-10 space-y-1 text-center"><dl><dt class="sr-only">Published on</dt><dd class="text-base leading-6 font-medium text-gray-500"><time datetime="2021-09-20T12:00:00.000Z">September 20, 2021</time></dd></dl><h1 class="text-3xl leading-9 font-extrabold text-gray-900 tracking-tight sm:text-4xl sm:leading-10 md:text-5xl md:leading-14">Real-time emotion recognizing</h1></header><div class="divide-y xl:divide-y-0 divide-gray-200 xl:grid xl:grid-cols-4 xl:gap-x-10 pb-16 xl:pb-20" style="grid-template-rows:auto 1fr;"><dl class="pt-6 pb-10 xl:pt-11 xl:border-b xl:border-gray-200"><dt class="sr-only">Authors</dt><dd><ul class="flex justify-center xl:block space-x-8 sm:space-x-12 xl:space-x-0 xl:space-y-8"><li class="flex items-center space-x-2"><img src="https://gravatar.com/avatar/6c1ae5231dcadf6b4297a6ddf6315478?s=80" alt="author image" class="w-10 h-10 rounded-full"><dl class="text-sm font-medium leading-5 whitespace-nowrap"><dt class="sr-only">Name</dt><dd class="text-gray-900">Tan Ngoc Pham</dd><dt class="sr-only">Linkedin</dt><dd><a href="https://linkedin.com/in/ngctnnnn" target="_blank" rel="noopnener noreferrer" class="link">ngctnnnn</a></dd></dl></li></ul></dd></dl><div class="divide-y divide-gray-200 xl:pb-0 xl:col-span-3 xl:row-span-2"><div style="position:relative;" class="prose max-w-none pt-10 pb-8"><div><p>Introduce a deep learning approach to the problem of recognizing emotions in real time. <p align="center"><img width="400px" height="100%" src="/demo-emotion-recognizing.png" alt="demo-emotion"></p></p><hr><h4 id="table-of-contents" tabindex="-1">Table of contents <a class="header-anchor" href="#table-of-contents" aria-hidden="true">#</a></h4><ol><li><a href="#1-introduction">Introduction</a></li><li><a href="#2-dataset">Dataset</a></li><li><a href="#3-proposed-architecture">Proposed architecture</a></li><li><a href="#4-references">References</a></li></ol><hr><h4 id="_1-introduction" tabindex="-1">1. Introduction <a class="header-anchor" href="#_1-introduction" aria-hidden="true">#</a></h4><p>There is a large number of neural networks nowadays to help us in almost every aspect of our life. In addition, we realize that different problems often require different types of networks. In this problem, I choose to use VGGFace network, or it is also called as Deep Face architecture.</p><p>VGGFace architecture was first introduced to solve the problem of recognizing humans&#39; face (i think it is called as Deep Face at first due to that reason, in my opinion).</p><div align="center"><iframe width="560" height="315" src="https://www.youtube.com/embed/IQ9qnqSi3gc" frameborder="0" allow="accelerometer; autoplay; encrypted-media gyroscope; picture-in-picture" allowfullscreen></iframe></div><p>With that reason in mind, i think that VGGFace would perform well on other problems relevant to our faces as in the problem of emotion recognizing.</p><h4 id="_2-dataset" tabindex="-1">2. Dataset <a class="header-anchor" href="#_2-dataset" aria-hidden="true">#</a></h4><p>The data using in this research is taken from <a href="https://www.kaggle.com/msambare/fer2013" target="_blank" rel="noopener noreferrer">Kaggle&#39;s FER-2013</a>.</p><blockquote><p>The data consists of 48x48 pixel grayscale images of faces. The faces have been automatically registered so that the face is more or less centred and occupies about the same amount of space in each image. The task is to categorize each face based on the emotion shown in the facial expression into one of seven categories (0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral). The training set consists of 28,709 examples and the public test set consists of 3,589 examples.</p></blockquote><p>However, in order to get a sufficient data for my model training, as well as avoiding imbalance between data classes, i just take out 3 most important emotions which are happy, sad and neutral. I also get rid of the testing phase due to the limitation in data. The training set is divided into 2 smaller sets, which are training set (80%) and validation set (20%).</p><h4 id="_3-proposed-architecture" tabindex="-1">3. Proposed architecture <a class="header-anchor" href="#_3-proposed-architecture" aria-hidden="true">#</a></h4><p>The originally proposed VGGFace architecture was shown as: <p align="center"><img src="https://i1.wp.com/sefiks.com/wp-content/uploads/2019/04/vgg-face-architecture.jpg?ssl=1" alt="vggface-architecture"><div algin="center"><figcaption><b>Fig 1.</b> Visualization of VGGFace architecture</figcaption></div></p></p><p>However, i did some minor change in the original architecture to give out a better performance to my own problem. In details, there is an extra layer after the second one, an extra dense layer in the fully connected one, the activation function utilized is <a href="https://www.mygreatlearning.com/blog/relu-activation-function/" target="_blank" rel="noopener noreferrer">ReLU</a> and some dropout layer.</p><p>The detailed model is shown as:</p><div class="language-python"><pre><code><span class="token triple-quoted-string string">&#39;&#39;&#39; First layer &#39;&#39;&#39;</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Conv2D<span class="token punctuation">(</span>filters<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                input_shape<span class="token operator">=</span><span class="token punctuation">(</span>img_width<span class="token punctuation">,</span> img_height<span class="token punctuation">,</span> img_depth<span class="token punctuation">)</span><span class="token punctuation">,</span> 
                activation<span class="token operator">=</span><span class="token string">&#39;relu&#39;</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">&#39;same&#39;</span><span class="token punctuation">,</span>
                kernel_initializer<span class="token operator">=</span><span class="token string">&#39;he_normal&#39;</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>BatchNormalization<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Conv2D<span class="token punctuation">(</span>filters<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                activation<span class="token operator">=</span><span class="token string">&#39;relu&#39;</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">&#39;same&#39;</span><span class="token punctuation">,</span>
                kernel_initializer<span class="token operator">=</span><span class="token string">&#39;he_normal&#39;</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>BatchNormalization<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>MaxPool2D<span class="token punctuation">(</span>pool_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Dropout<span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token triple-quoted-string string">&#39;&#39;&#39; Second layer &#39;&#39;&#39;</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Conv2D<span class="token punctuation">(</span>filters<span class="token operator">=</span><span class="token number">128</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                activation<span class="token operator">=</span><span class="token string">&#39;relu&#39;</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">&#39;same&#39;</span><span class="token punctuation">,</span>
                kernel_initializer<span class="token operator">=</span><span class="token string">&#39;he_normal&#39;</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>BatchNormalization<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Conv2D<span class="token punctuation">(</span>filters<span class="token operator">=</span><span class="token number">128</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                activation<span class="token operator">=</span><span class="token string">&#39;relu&#39;</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">&#39;same&#39;</span><span class="token punctuation">,</span>
                kernel_initializer<span class="token operator">=</span><span class="token string">&#39;he_normal&#39;</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>BatchNormalization<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>MaxPool2D<span class="token punctuation">(</span>pool_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Dropout<span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token triple-quoted-string string">&#39;&#39;&#39; Extra layer &#39;&#39;&#39;</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Conv2D<span class="token punctuation">(</span>filters<span class="token operator">=</span><span class="token number">256</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                activation<span class="token operator">=</span><span class="token string">&#39;relu&#39;</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">&#39;same&#39;</span><span class="token punctuation">,</span>
                kernel_initializer<span class="token operator">=</span><span class="token string">&#39;he_normal&#39;</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>BatchNormalization<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Conv2D<span class="token punctuation">(</span>filters<span class="token operator">=</span><span class="token number">256</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                activation<span class="token operator">=</span><span class="token string">&#39;relu&#39;</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">&#39;same&#39;</span><span class="token punctuation">,</span>
                kernel_initializer<span class="token operator">=</span><span class="token string">&#39;he_normal&#39;</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>BatchNormalization<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>MaxPool2D<span class="token punctuation">(</span>pool_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Dropout<span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token triple-quoted-string string">&#39;&#39;&#39; Fully connected layer &#39;&#39;&#39;</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Dense<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span>activation<span class="token operator">=</span><span class="token string">&#39;relu&#39;</span><span class="token punctuation">,</span>kernel_initializer<span class="token operator">=</span><span class="token string">&#39;he_normal&#39;</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>BatchNormalization<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Dropout<span class="token punctuation">(</span><span class="token number">0.6</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Dense<span class="token punctuation">(</span>num_classes<span class="token punctuation">,</span>activation<span class="token operator">=</span><span class="token string">&#39;softmax&#39;</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre></div><p>Additionally, i also create a callback with a demonstration as: the learning rate would reduce with a factor of 0.5 once 7 continuous epochs do not improve their performance; and an early stopping is set once the performance does not improve in 7 consecutive epochs.</p><div class="language-python"><pre><code>early_stopping <span class="token operator">=</span> EarlyStopping<span class="token punctuation">(</span>
    monitor<span class="token operator">=</span><span class="token string">&#39;val_accuracy&#39;</span><span class="token punctuation">,</span>
    min_delta<span class="token operator">=</span><span class="token number">0.00005</span><span class="token punctuation">,</span>
    patience<span class="token operator">=</span><span class="token number">11</span><span class="token punctuation">,</span>
    verbose<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>
    restore_best_weights<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>

lr_scheduler <span class="token operator">=</span> ReduceLROnPlateau<span class="token punctuation">(</span>
    monitor<span class="token operator">=</span><span class="token string">&#39;val_accuracy&#39;</span><span class="token punctuation">,</span>
    factor<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">,</span>
    patience<span class="token operator">=</span><span class="token number">7</span><span class="token punctuation">,</span>
    min_lr<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">7</span><span class="token punctuation">,</span>
    verbose<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>
</code></pre></div><p>The training process is shown as: <p align="center"><img src="/emo-recog-trainning-process.png" alt="training-process"><div algin="center"></div></p></p><p>We can notice our model just has to go through 43 epochs before coming to the early convergence.</p><p>Moreover, since this model is rather huge and we can not use the whole model to predict in such a limited time when we harness our model in real-time. I would save the weights from model into a json model, and in main program, we just have to load our weights in the json only.</p><div class="language-python"><pre><code>fer_json <span class="token operator">=</span> model<span class="token punctuation">.</span>to_json<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">&quot;model/vgg-face-model.json&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;w&quot;</span><span class="token punctuation">)</span> <span class="token keyword">as</span> json_file<span class="token punctuation">:</span>
    json_file<span class="token punctuation">.</span>write<span class="token punctuation">(</span>fer_json<span class="token punctuation">)</span>
model<span class="token punctuation">.</span>save_weights<span class="token punctuation">(</span><span class="token string">&quot;model/vgg-face.h5&quot;</span><span class="token punctuation">)</span>
</code></pre></div><p>And voilà, here is our final result after training the model and you can see its performance exceeds our expectation. <p align="center"><img src="/emo-detect-demo.png" width="80%" alt="demo-project"></p></p><p>Detailed implementation here: <a href="https://github.com/ngctnnnn/RealTime-Emotion-Recognizer" target="_blank" rel="noopener noreferrer">ngctnnnn/RealTime-Emotion-Recognizer</a></p><h4 id="_4-references" tabindex="-1">4. References <a class="header-anchor" href="#_4-references" aria-hidden="true">#</a></h4><p>[1] Qawaqneh et al. (2017). Deep convolutional neural network for age estimation based on VGG-face model. <em>arXiv:1709.01664</em>.</p><p>[2] I. J. Goodfellow et al. Challenges in representation learning: A report on three machine learning contests. <em>Neural Networks, 64:59--63, 2015. Special Issue on &quot;Deep Learning of Representations&quot;</em>.</p></div></div></div><footer class="text-sm font-medium leading-5 divide-y divide-gray-200 xl:col-start-1 xl:row-start-2"><div class="pt-8"><a class="link" href="/">← Back to the blog</a></div></footer></div><footer class="text-sm font-medium leading-5 divide-y divide-gray-200 xl:col-start-1 xl:row-start-2" style="display:inline-flex;justify-content:space-between;width:100%;"><div style="display:inline-flex;justify-content:space-between;width:100%;"><div class="py-8"><h2 class="text-xs tracking-wide uppercase text-gray-500"> Previous Article </h2><div class="link"><a href="/posts/detect-covid19-dcnn.html">← Detect COVID-19 with Deep Learning</a></div></div><!----></div></footer></article></main></div></div>
    
    
    
  </body>
</html>